## 1.模型直接回答  

### 导入相关模块  
```commandline
import os
from langchain_openai import OpenAI
from langchain_community.llms import HuggingFaceHub
import os
os.environ['OPENAI_API_KEY'] = 'sk-'
```
### 导入模型进行回答
```commandline
llm = OpenAI(
             temperature=0.9,
             max_tokens = 256)#temperature越小回答越严谨
prompt = f"你的爸爸是谁“
response = llm(prompt)
```
  
## 2.用prompt模块回答
优点：更具专用性，更适用于一个专用的系统
```commandline
restaurant_template = """
你是一个数据科学家，请你将以下数据{data}按值从大到小排列
"""

prompt = PromptTemplate(
    input_variables=["restaurant_desription"],
    template=restaurant_template,
)
```